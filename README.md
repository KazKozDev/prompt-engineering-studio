# üöÄ Prompt Engineering Studio

A powerful web application that transforms your simple queries into advanced, optimized prompts using cutting-edge prompt engineering techniques. Support for multiple LLM providers including Gemini, Ollama, and more.

![Prompt Engineering Studio Demo](https://img.shields.io/badge/Status-Working-brightgreen) ![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?logo=typescript&logoColor=white) ![Vite](https://img.shields.io/badge/Vite-646CFF?logo=vite&logoColor=white)

## ‚ú® Features

- **26+ Prompt Engineering Techniques** - From basic Zero-Shot to advanced Tree of Thoughts
- **Multi-Provider Support** - Works with Gemini, Ollama (local), and more
- **Real-time Generation** - Generate enhanced prompts instantly
- **Copy & Use** - One-click copy of generated prompts
- **Academic References** - Each technique includes paper citations and arXiv links
- **Modern UI** - Clean, responsive interface built with modern web technologies

## üéØ Supported Prompt Techniques

### Basic Techniques
- **Zero-Shot Prompting** - Direct queries without examples
- **Few-Shot Prompting** - Learning from input-output examples
- **Role Prompting** - Assigning expert roles to the model

### Advanced Reasoning
- **Chain-of-Thought** - Step-by-step reasoning processes
- **Tree of Thoughts** - Multiple solution path exploration
- **Graph of Thoughts** - Complex dependency modeling
- **ReAct** - Reasoning and Acting in structured cycles

### Meta-Cognitive Approaches
- **Self-Consistency** - Multiple solution verification
- **Self-Critique** - Critical evaluation of responses
- **Metacognitive Prompting** - Thinking about thinking
- **Reflection** - Post-solution analysis

### Modern Techniques (2023-2025)
- **Meta-Prompting** - LM conducting multiple expert queries
- **TextGrad Optimization** - Automatic prompt improvement
- **System Prompt Optimization** - Meta-learning approaches
- **Visual Chain-of-Thought** - Multimodal reasoning

## üîß Supported LLM Providers

### ü§ñ Google Gemini
- **Models**: `gemini-2.5-flash-preview-04-17`, `gemini-pro`, etc.
- **Setup**: Requires API key from [Google AI Studio](https://makersuite.google.com/)
- **Cost**: Pay-per-use

### üè† Ollama (Local)
- **Models**: `llama3.2`, `llama2`, `codellama`, `mistral`, etc.
- **Setup**: Runs locally, no API key required
- **Cost**: Free (after initial setup)
- **Privacy**: Complete data privacy, offline capable

### üîÆ OpenAI (Coming Soon)
- **Status**: Implementation planned
- **Models**: GPT-4, GPT-3.5, etc.

## üöÄ Quick Start

### Prerequisites
- **Node.js** (v16 or higher)
- **npm** or **yarn**

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/KazKozDev/prompt-engineering-studio.git
   cd prompt-engineering-studio
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Choose your LLM provider and set it up:**

#### Option A: Google Gemini
```bash
# Create .env.local file
echo "GEMINI_API_KEY=your_api_key_here" > .env.local
```

#### Option B: Ollama (Local)
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama server
ollama serve

# Pull a model (in another terminal)
ollama pull llama3.2
```

4. **Start the development server**
   ```bash
   npm run dev
   ```

5. **Open in browser**
   ```
   http://localhost:5173
   ```

## üîß Usage

1. **Configure LLM Provider**
   - Select your provider (Gemini/Ollama) from the dropdown
   - Enter model name (e.g., `llama3.2` for Ollama)
   - For Gemini: Enter your API key
   - Click "Save LLM Settings"

2. **Enter Your Query**
   - Type your question or task in the text area
   - Example: "Explain quantum computing"

3. **Select Techniques**
   - Choose one or more prompt engineering techniques
   - Use "Select All" for comprehensive analysis

4. **Generate Enhanced Prompts**
   - Click "Generate Enhanced Prompts"
   - Wait for AI to create optimized versions
   - Copy and use the generated prompts with any LLM

## üìä Example Transformation

**Input Query:**
```
"Explain machine learning"
```

**Chain-of-Thought Enhanced:**
```
You are an expert in machine learning and data science. I need you to explain machine learning in a comprehensive way using step-by-step reasoning.

Please follow this structure:
1. First, define what machine learning is at its core
2. Then, explain the main types of machine learning
3. Provide concrete examples for each type
4. Explain how the learning process works
5. Discuss practical applications
6. Finally, summarize the key concepts

Please think through each step carefully and show your reasoning process as you build up the explanation from basic concepts to more complex applications.
```

## üß™ Testing

### Test Ollama Connection
```bash
node test-ollama.js
```

### Run in Development
```bash
npm run dev
```

### Build for Production
```bash
npm run build
npm run preview
```

## üìö Academic References

This project implements techniques from cutting-edge research papers:

- **Chain-of-Thought**: Wei et al. (2022) - [arXiv:2201.11903](https://arxiv.org/abs/2201.11903)
- **Tree of Thoughts**: Yao et al. (2023) - [arXiv:2305.10601](https://arxiv.org/abs/2305.10601)
- **ReAct**: Yao et al. (2022) - [arXiv:2210.03629](https://arxiv.org/abs/2210.03629)
- **Meta-Prompting**: Suzgun & Kalai (2024) - [arXiv:2401.12954](https://arxiv.org/abs/2401.12954)
- [... and 22+ more techniques with full citations]

## üõ†Ô∏è Tech Stack

- **Frontend**: TypeScript, HTML5, CSS3
- **Build Tool**: Vite
- **LLM Integration**: Google GenAI SDK, Ollama API
- **Styling**: Modern CSS with responsive design
- **Icons**: Material Symbols

## ü§ù Contributing

Contributions are welcome! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit changes**: `git commit -m 'Add amazing feature'`
4. **Push to branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Adding New Techniques
To add a new prompt engineering technique:

1. Add the technique object to `promptTechniques` array in `index.tsx`
2. Include proper academic citation
3. Test with multiple LLM providers
4. Update documentation

### Adding New LLM Providers
1. Extend the `initializeGenAI()` function
2. Add provider-specific UI elements
3. Update configuration handling
4. Add comprehensive error handling

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Research papers and authors of prompt engineering techniques
- Google for the Gemini API
- Ollama team for local LLM infrastructure
- Open source community for tools and libraries

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/KazKozDev/prompt-engineering-studio/issues)
- **Discussions**: [GitHub Discussions](https://github.com/KazKozDev/prompt-engineering-studio/discussions)
- **Documentation**: This README and inline code comments

---

**Made with ‚ù§Ô∏è for the AI and prompt engineering community**
